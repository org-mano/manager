#!/usr/bin/env python2

import os
import pwd
import json
import stat
import shutil
import logging
import argparse
import subprocess

ORIGINAL_NGINX_LOCATION = '/etc/nginx/conf.d/rest-location.cloudify'
CONFIGFILE = '/opt/cloudify/sudo.json'
LOGFILE = '/var/log/cloudify/cloudify-cluster.log'
logging.basicConfig(filename=LOGFILE, level=logging.DEBUG)
PG_HBA_SEPARATOR = '# END CLUSTER PG_HBA\n'
RECOVERY_UNIT_NAME = 'cloudify-consul-recovery-watcher'


def promote(config):
    services = config['manager_services']
    subprocess.check_call(['systemctl', 'enable'] + services)
    subprocess.check_call(['systemctl', 'start'] + services)


def follow(config, master):
    services = config['master_only_services']
    logging.debug('disabling: {0}'.format(services))
    subprocess.check_call(['systemctl', 'stop'] + services)
    subprocess.check_call(['systemctl', 'disable'] + services)


def update_nginx(config, allow=False, location=None):
    resources = config['resources']
    backup_path = os.path.join(resources, 'location_backup')
    if not os.path.exists(backup_path):
        shutil.copy(ORIGINAL_NGINX_LOCATION, backup_path)
    if allow:
        shutil.copy(backup_path, ORIGINAL_NGINX_LOCATION)
    elif location:
        shutil.copy(os.path.join(resources, location),
                    ORIGINAL_NGINX_LOCATION)
    else:
        raise ValueError('exactly one of allow, location must be specified')
    subprocess.check_call(['systemctl', 'reload', 'nginx'])


def update_db_settings(config, data_dir, cloudify_db, cloudify_user,
                       replication_user, hosts):
    pg_hba_path = os.path.join(data_dir, 'pg_hba.conf')
    with open(pg_hba_path, 'r+') as f:
        pg_hba_data = f.read()
        if PG_HBA_SEPARATOR in pg_hba_data:
            _, _, pg_hba_data = pg_hba_data.partition(PG_HBA_SEPARATOR)
        f.seek(0)
        f.truncate()
        f.write('# hosts: {0}\n'.format(hosts))
        for host in hosts:
            f.write('hostssl\treplication\t{user}\t{host}/32\t'
                    'md5 clientcert=1\n'
                    .format(user=replication_user, host=host))
            f.write('hostssl\t{cloudify_db}\t{cloudify_user}\t{host}/32\t'
                    'md5 clientcert=1\n'
                    .format(cloudify_db=cloudify_db,
                            cloudify_user=cloudify_user, host=host))
        f.write(PG_HBA_SEPARATOR)
        f.write(pg_hba_data)
    subprocess.check_call(['systemctl', 'reload', 'cloudify-postgresql'])


def reload_consul(config):
    subprocess.check_call(['systemctl', 'reload', 'cloudify-consul'])


def restart_consul(config):
    subprocess.check_call(['systemctl', 'restart', 'cloudify-consul'])


def minority_rejoin(config, start):
    rejoin_services = [
        'cloudify-check-runner',
        'cloudify-handler-runner',
        'cloudify-consul'
    ]
    if start:
        shutil.rmtree('/opt/consul/data')
        subprocess.check_call(['systemctl', 'start'] + rejoin_services)
    else:
        subprocess.check_call(['systemctl', 'stop'] + rejoin_services)


def iptables(config, block, hosts):
    if block:
        for addr in hosts:
                for chain, flag in [('INPUT', '-s'), ('OUTPUT', '-d')]:
                    for port in [8500, 15432]:
                        for direction in ['--sport', '--dport']:
                            subprocess.check_call(['iptables', '-A', chain,
                                                   '-p', 'tcp', flag, addr,
                                                   direction, str(port),
                                                   '-j', 'ACCEPT'])
                    for proto in ['tcp', 'udp']:
                        subprocess.check_call(['iptables', '-A', chain, '-p',
                                               proto, flag, addr, '-j',
                                               'DROP'])
    else:
        for addr in hosts:
            for chain, flag in [('INPUT', '-s'), ('OUTPUT', '-d')]:
                for port in [8500, 15432]:
                    for direction in ['--sport', '--dport']:
                        subprocess.check_call(['iptables', '-D', chain,
                                               '-p', 'tcp', flag, addr,
                                               direction, str(port),
                                               '-j', 'ACCEPT'])
                for proto in ['tcp', 'udp']:
                    subprocess.check_call(['iptables', '-D', chain, '-p',
                                           proto, flag, addr, '-j', 'DROP'])

    rules = subprocess.check_output(['iptables-save'])
    with open('/etc/sysconfig/iptables', 'w') as f:
        f.write(rules)


def start_recovery(config):
    subprocess.check_call(['systemctl', 'enable', RECOVERY_UNIT_NAME])
    subprocess.check_call(['systemctl', 'start', RECOVERY_UNIT_NAME])


def disable_recovery(config):
    subprocess.check_call(['systemctl', 'disable', RECOVERY_UNIT_NAME])


def partitioned_cluster_changed(config, executable, host, port):
    subprocess.check_call([
        'systemd-run', '--unit', 'partitioned_cluster_changed',
        executable, '--addr', host, '--port', port
    ])


def promote_db(config, trigger_file):
    with open(trigger_file, 'w') as f:
        f.write('trigger')


def follow_db(config, trigger_file, data_dir, owner, connstring):
    subprocess.check_call(['systemctl', 'stop', 'cloudify-postgresql'])

    recovery_file = os.path.join(data_dir, 'recovery.conf')
    with open(recovery_file, 'w') as f:
        f.write("standby_mode = 'on'\n")
        f.write("primary_conninfo = '{}'\n".format(connstring))
        f.write("trigger_file = '{}'\n".format(trigger_file))
    user = pwd.getpwnam(owner)
    os.chown(recovery_file, user.pw_uid, user.pw_gid)

    try:
        os.remove(trigger_file)
    except OSError:
        pass
    subprocess.check_call(['systemctl', 'start', 'cloudify-postgresql'])


def recreate_db_directory(config, data_dir, owner):
    subprocess.check_call(['systemctl', 'stop', 'cloudify-postgresql'])
    shutil.rmtree(data_dir, ignore_errors=True)
    os.mkdir(data_dir)
    db_owner = pwd.getpwnam(owner)
    os.chown(data_dir, db_owner.pw_uid, db_owner.pw_gid)
    os.chmod(data_dir, stat.S_IRWXU)


def standby_clone(config, connstring, owner, data_dir):
    try:
        subprocess.check_call(['sudo', '-u', owner,
                               'pg_basebackup',
                               '-d', connstring,
                               '-D', data_dir])
    except Exception as e:
        raise ValueError(e.output)


def consul_peers(config, data_dir, peers):
    with open(os.path.join(data_dir, 'raft/peers.json'), 'w') as f:
        json.dump(peers, f)


def leave_cluster(config):
    subprocess.check_call(['/opt/consul/consul', 'leave'])

    # when leaving the cluster, stop all services
    services = config['manager_services']
    subprocess.check_call(['systemctl', 'disable'] + services)
    subprocess.check_call(['systemctl', 'stop'] + services)

    # also stop the internal services that we normally don't health check
    # the ordering here is important - first stop all the manager services
    # (if running), then try to leave the consul cluster gracefully,
    # then stop consul, and stop HandlerRunner last - if we try to
    # stop consul before HandlerRunner, it will start trying to failover
    internal_services = ['consul', 'cloudify-consul-watcher',
                         'cloudify-check-runner', 'cloudify-handler-runner',
                         'cloudify-consul-recovery-watcher']
    subprocess.check_call(['systemctl', 'disable'] + internal_services)
    subprocess.check_call(['systemctl', 'stop'] + internal_services)


handlers = {
    'promote': promote,
    'follow': follow,
    'nginx': update_nginx,
    'postgresql': update_db_settings,
    'reload_consul': reload_consul,
    'restart_consul': restart_consul,
    'minority_rejoin': minority_rejoin,
    'iptables': iptables,
    'start_recovery': start_recovery,
    'disable_recovery': disable_recovery,
    'partitioned_cluster_changed': partitioned_cluster_changed,
    'promote_db': promote_db,
    'follow_db': follow_db,
    'recreate_db_directory': recreate_db_directory,
    'standby_clone': standby_clone,
    'consul_peers': consul_peers,
    'leave': leave_cluster
}


# no if-name-main: this script is not intended to be imported ever
parser = argparse.ArgumentParser()
subparsers = parser.add_subparsers(dest='command')
promote_parser = subparsers.add_parser('promote')

follow_parser = subparsers.add_parser('follow')
follow_parser.add_argument('--master', required=True)

update_nginx_parser = subparsers.add_parser('nginx')
update_nginx_parser.add_argument('--allow', action='store_true')
update_nginx_parser.add_argument('--location')

update_db_settings = subparsers.add_parser('postgresql')
update_db_settings.add_argument('--data-dir', required=True, dest='data_dir')
update_db_settings.add_argument('hosts', nargs='+', metavar='H')
update_db_settings.add_argument('--cloudify-db', required=True)
update_db_settings.add_argument('--cloudify-user', required=True)
update_db_settings.add_argument('--replication-user', required=True)


reload_consul_parser = subparsers.add_parser('reload_consul')

restart_consul_parser = subparsers.add_parser('restart_consul')

minority_rejoin_parser = subparsers.add_parser('minority_rejoin')
minority_rejoin_parser.add_argument('--start', default=False,
                                    action='store_true')

iptables_parser = subparsers.add_parser('iptables')
iptables_parser.add_argument('--block', default=False,
                             action='store_true')
iptables_parser.add_argument('hosts', nargs='+', metavar='H')

start_recovery_parser = subparsers.add_parser('start_recovery')

disable_recovery_parser = subparsers.add_parser('disable_recovery')

partitioned_changed_parser = subparsers.add_parser(
    'partitioned_cluster_changed')
partitioned_changed_parser.add_argument('--executable', required=True)
partitioned_changed_parser.add_argument('--host', required=True)
partitioned_changed_parser.add_argument('--port', required=True)

promote_db_parser = subparsers.add_parser('promote_db')
promote_db_parser.add_argument('--trigger-file', required=True,
                               dest='trigger_file')

standby_follow_parser = subparsers.add_parser('follow_db')
standby_follow_parser.add_argument('--trigger-file', dest='trigger_file')
standby_follow_parser.add_argument('--data-dir', dest='data_dir')
standby_follow_parser.add_argument('--connstring')
standby_follow_parser.add_argument('--owner')

recreate_db_parser = subparsers.add_parser('recreate_db_directory')
recreate_db_parser.add_argument('--data-dir', dest='data_dir')
recreate_db_parser.add_argument('--owner')

standby_clone_parser = subparsers.add_parser('standby_clone')
standby_clone_parser.add_argument('--connstring')
standby_clone_parser.add_argument('--data-dir', dest='data_dir')
standby_clone_parser.add_argument('--owner')

consul_peers_parser = subparsers.add_parser('consul_peers')
consul_peers_parser.add_argument('--data-dir', dest='data_dir')
consul_peers_parser.add_argument('peers', nargs='+', metavar='H')

leave_parser = subparsers.add_parser('leave')


args = vars(parser.parse_args())
command = args.pop('command')
with open(CONFIGFILE) as f:
    config = json.load(f)
logging.debug('running {0} with args {1}'.format(command, args))
handler = handlers[command]
try:
    handler(config=config, **args)
except Exception as e:
    logging.exception('error in {0}'.format(command))
    raise ValueError(e.output)
