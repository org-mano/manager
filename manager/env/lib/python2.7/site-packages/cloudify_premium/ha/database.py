########
# Copyright (c) 2016 GigaSpaces Technologies Ltd. All rights reserved
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#        http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
#    * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#    * See the License for the specific language governing permissions and
#    * limitations under the License.

from __future__ import absolute_import

import os
import grp
import pwd
import stat
import json
import time
import base64
import shutil
import logging
import tempfile
import urlparse
import subprocess
from contextlib import contextmanager

from cloudify_premium.ha import (consul,
                                 cluster_status,
                                 node_status,
                                 services,
                                 sudo,
                                 ssl,
                                 systemd,
                                 utils)

try:
    import psycopg2
except ImportError:
    psycopg2 = None


ORIGINAL_PS_SERVICE_NAME = 'postgresql-9.5'
ORIGINAL_DATA_DIR = '/var/lib/pgsql/9.5/data'
PS_SERVICE_NAME = 'postgresql'
POSTGRES_BIN_DIR = '/usr/pgsql-9.5/bin/'
PG_HBA_SEPARATOR = '# END CLUSTER PG_HBA\n'
DB_PORT = 15432
DB_REPLICATION_USER = 'cloudify_replicator'
DB_QUERY_USER = 'cloudify_minority'
TRIGGER_FILE = '/tmp/postgresql.trigger'
POSTGRESQL_CONNECT_TIMEOUT = 3  # seconds
POSTGRESQL_USER = 'postgres'
SSL_CLIENT_CERT = '/etc/cloudify/ssl/postgresql_client.crt'
SSL_CA_CERT = '/etc/cloudify/ssl/postgresql_ca.crt'

# need two key files because postgres insists the key is 0600, so can't give
# group access - one is owned by the cluster user, one by the postgresql user
SSL_CLIENT_KEY = '/etc/cloudify/ssl/postgresql_client.key'
SSL_POSTGRES_CLIENT_KEY = '/etc/cloudify/ssl/postgresql_client_pg.key'

# the distributed lock used when doing maintenance db operations
# (eg. restarting postgresql) that shouldn't lead to electing a new master
# Operations using this lock:
#   - configuring a new db in the cluster (in the create_cluster_node command)
#   - choosing a new cluster master during failover (in db_online_handler)
#   - standby_clone
DB_LOCK_KEY = 'db_master'
logger = logging.getLogger(__name__)


class Database(systemd.SystemdManaged):
    """Interface for the database service."""
    unit_source = 'resources/cloudify-postgresql.service'

    @classmethod
    def create(cls, data_dir, owner=POSTGRESQL_USER, *args, **kwargs):
        """Create the database service, preparing the storage directories."""
        if not os.path.exists(data_dir):
            os.mkdir(data_dir)
            db_owner = pwd.getpwnam(owner)
            os.chown(data_dir, db_owner.pw_uid, db_owner.pw_gid)
            os.chmod(data_dir, stat.S_IRWXU)  # 0700 is required by pg
        return cls(data_dir=data_dir, owner=owner, *args, **kwargs)

    def __init__(self, data_dir='/var/pgdata', port=DB_PORT, owner='postgres',
                 service_name=PS_SERVICE_NAME, *args, **kwargs):
        super(Database, self).__init__(service_name=service_name,
                                       *args, **kwargs)
        self.data_dir = data_dir
        self.port = port
        self._owner = owner

    @property
    def replication(self):
        return _ReplicationConfig(self)

    @property
    def config(self):
        return _DBConfig(self)

    def configure(self):
        # before rendering the systemd unit file, set required attributes:
        # - postgres bin dir can be retrieved from the restservice config
        self.bin_path = utils.load_restservice_config()['postgresql_bin_path']
        super(Database, self).configure()

    def start(self, wait_writable=True):
        """Start the database service and wait until it's ready.

        :param wait_writable: wait until the database accepts writes.
            Otherwise, simply wait until it accepts connections.
        """
        super(Database, self).start()
        self._wait_until_ready(wait_writable=wait_writable)

    def restart(self):
        # after restarting the db, restservice needs to be restarted as well,
        # because otherwise it might take it a long time to reconnect
        # to the database (or wouldn't be able to reconnect at all)
        super(Database, self).restart()
        services.RESTSERVICE.restart()

    def clone(self, destination_data_dir):
        """Create a new database service by copying the data from this one.

        This will create a new postgresql data directory, and use the builtin
        replication to copy the data. Note that this might take this database
        offline while enabling replication.
        """
        new_db = Database.create(destination_data_dir)

        db_owner = pwd.getpwnam(self._owner)
        archives_dir = tempfile.mkdtemp()
        os.chown(archives_dir, db_owner.pw_uid, db_owner.pw_gid)

        with self._enable_local_replication():
            self.run(['pg_basebackup', '-D', destination_data_dir, '--xlog'])
            recovery_path = os.path.join(destination_data_dir, 'recovery.conf')
            with open(recovery_path, 'w') as f:
                f.write("""
                    restore_command = 'cp {0}/%f %p'
                """.format(archives_dir))
            os.chown(recovery_path, db_owner.pw_uid, db_owner.pw_gid)

        return new_db

    def delete(self):
        logger.debug('Removing database: {0}'.format(self.data_dir))
        self.stop()
        shutil.rmtree(self.data_dir, ignore_errors=True)

    def run(self, command, env=None):
        if env is None:
            env = {}

        env.setdefault('PGPORT', str(self.port))
        if not os.path.isabs(command[0]):
            command = list(command)
            command[0] = os.path.join(POSTGRES_BIN_DIR, command[0])

        # this can also be run from a handler, as the postgres user; in that
        # case, there's no need to sudo (and indeed, sudo is not allowed)
        if os.getuid() != pwd.getpwnam(self._owner).pw_uid:
            command = ['sudo', '-u', self._owner, '-E'] + command

        output = subprocess.check_output(command, env=env,
                                         stderr=subprocess.STDOUT)
        logger.debug('Running {0} {1}: {2}'.format(command, env, output))

    def createuser(self, username, password):
        sql_command = ("CREATE user {} WITH PASSWORD '{}' REPLICATION LOGIN"
                       .format(username, password))
        logger.debug(sql_command)
        return self.run(['psql', '-c', sql_command])

    @contextmanager
    def _enable_local_replication(self):
        """Under the contextmanager, this database has replication enabled.

        This entails setting max_wal_senders, wal_level, and archiving in the
        postgresql.conf, and allowing the replication connection in pg_hba.
        """
        pg_hba_path = os.path.join(self.data_dir, 'pg_hba.conf')
        config_path = os.path.join(self.data_dir, 'postgresql.conf')

        with open(pg_hba_path, 'r+') as pg_hba:
            original_pg_hba = pg_hba.read()
            pg_hba.seek(0)
            pg_hba.truncate()
            pg_hba.write('local\treplication\tpostgres\t\tpeer\n')
            pg_hba.write(original_pg_hba)

        with open(config_path, 'r+') as f:
            original_postgresql_conf = f.read()
            f.write("""
                max_wal_senders=1
                wal_level=hot_standby
                archive_mode=on
                archive_command='cp %p /tmp/archives/%f'
            """)

        self.restart()
        try:
            yield
        finally:
            with open(pg_hba_path, 'w') as pg_hba:
                pg_hba.write(original_pg_hba)

            with open(config_path, 'r+') as f:
                f.write(original_postgresql_conf)
            self.restart()

    def _wait_until_ready(self, retries=20, retry_interval=1,
                          wait_writable=True):
        if wait_writable:
            wait_for_postgres()
        else:
            utils.wait_for_port(host='127.0.0.1', port=self.port)


class OriginalDatabase(Database):
    """Specialized version of Database that represens the original cloudify
    manager postgresql installation.
    """
    def __init__(self):
        super(OriginalDatabase, self).__init__(
            data_dir=ORIGINAL_DATA_DIR,
            service_name=ORIGINAL_PS_SERVICE_NAME,
            append_prefix=False,
            port=5432)

    def configure(self):
        raise RuntimeError('Original database should already be configured '
                           'on the manager!')


class _DBConfig(object):
    wal_keep_segments = 5

    def __init__(self, db):
        self._db = db
        self.data_dir = db.data_dir

    def deploy_config(self):
        """Change postgresql.conf settings to allow replication.

        Return if the settings changed compared to the previous.
        """
        # TODO: make postgres config replication_slots configurable when we
        # need to support clusters bigger than 5 nodes
        self.port = self._db.port
        postgresql_conf_path = os.path.join(self.data_dir, 'postgresql.conf')

        # make sure this method is idempotent - only add the 'include'
        # directive to the config, if it's not in there yet. This is because
        # this method will be called to rerender the cluster.conf, from
        # a 'cluster changed' handler
        include = "include 'postgresql.cluster.conf'"
        with open(postgresql_conf_path) as f:
            postgresql_conf = f.read()

        if include not in postgresql_conf:
            with open(postgresql_conf_path, 'a') as f:
                f.write(include + '\n')

        cluster_conf_path = os.path.join(self.data_dir,
                                         'postgresql.cluster.conf')
        with open(cluster_conf_path, 'w') as f:
            utils.render_resource(f, 'resources/postgresql.cluster.conf',
                                  obj=self)
        db_user = pwd.getpwnam(self._db._owner)
        os.chown(cluster_conf_path, db_user.pw_uid, db_user.pw_gid)
        return True

    def prepare_pg_hba(self):
        """Allow the cluster members to access the replication conn in pg_hba.

        Return if the pg_hba config changed.
        """
        # TODO maybe remove this if the handler is enough now?
        pg_hba_path = os.path.join(self.data_dir, 'pg_hba.conf')
        hosts = [n['host_ip'] for n in cluster_status.nodes.values()]

        if node_status.get('pg_hba_hosts') == hosts:
            logger.debug('pg_hba hosts same as before: {0}'.format(hosts))
            return False
        node_status['pg_hba_hosts'] = hosts
        logger.debug('Allowing in pg_hba.conf: {0}'.format(hosts))

        restservice_config = utils.load_restservice_config()
        cloudify_db = restservice_config['postgresql_db_name']
        cloudify_user = cluster_status.db_credentials['user']

        with open(pg_hba_path, 'r+') as f:
            pg_hba_data = f.read()
            if PG_HBA_SEPARATOR in pg_hba_data:
                _, _, pg_hba_data = pg_hba_data.partition(PG_HBA_SEPARATOR)
            f.seek(0)
            f.truncate()
            # the cluster data needs to go first, otherwise preexisting
            # settings would overwrite it
            utils.render_resource(
                f,
                'resources/cluster_pg_hba.conf.tmpl',
                user=DB_REPLICATION_USER,
                hosts=hosts,
                # cloudify db connection is required for the "acive minority"
                # feature, to query for users.last_login-at
                cloudify_db=cloudify_db,
                cloudify_user=cloudify_user)
            f.write(PG_HBA_SEPARATOR)
            f.write(pg_hba_data)

        return True


class _ReplicationConfig(object):

    def __init__(self, db):
        self._db = db
        self._node_num = None

    def standby_clone(self, master_ip, master_port=DB_PORT, retries=20,
                      retry_interval=1):
        logger.debug('cloning from {0}'.format(master_ip))
        if self.is_already_following(master_ip):
            logger.debug('Already following {0}'.format(master_ip))
            return
        credentials = cluster_status.replication_credentials
        wait_for_postgres(cluster_status.master)

        connection_options = {
            'sslkey': SSL_POSTGRES_CLIENT_KEY,
            'sslcert': SSL_CLIENT_CERT,
            'sslrootcert': SSL_CA_CERT,
            'sslmode': 'verify-ca',
            'user': credentials['user'],
            'password': credentials['password'],
            'host': master_ip,
            'port': str(master_port)
        }
        connstring = ' '.join('{0}={1}'.format(k, v)
                              for k, v in connection_options.items())
        logger.debug('connstring {0}'.format(connstring))
        with utils.ConsulLock(DB_LOCK_KEY):
            for retry in range(retries):
                try:
                    sudo.run([
                        'standby_clone',
                        '--connstring', connstring,
                        '--data-dir', self._db.data_dir,
                        '--owner', self._db._owner
                    ])
                except subprocess.CalledProcessError:
                    logger.exception('error cloning (retry {0}/{1})'
                                     .format(retry, retries))
                    time.sleep(retry_interval)
                else:
                    logger.debug('cloning from {0} done'.format(master_ip))
                    break

    def standby_promote(self, promote_retries=20, promote_retry_interval=1):
        timeline = _get_timeline(False)
        logger.debug('standby_promote')
        if node_status.get('db') == 'master':
            logger.warning('promote: already master - skipping')
        else:
            logger.debug('promoting')
            sudo.run(['promote_db', '--trigger-file', TRIGGER_FILE])

        node_status['db'] = 'master'
        node_status.pop('db_following', None)

        # wait until the reported timeline changes - that means the standby
        # finished promoting; block until then
        for retry in range(promote_retries):
            new_timeline = _get_timeline(False)
            if new_timeline == timeline:
                logger.debug('timeline didnt change {0}'.format(new_timeline))
                time.sleep(promote_retry_interval)
            else:
                break

        for retry in range(promote_retries):
            try:
                conn = database_connection(replication=True)
            except psycopg2.DatabaseError as e:
                if 'authentication' not in e.message:
                    time.sleep(promote_retry_interval)
                    continue
                else:
                    logger.exception('promote usercheck')
            else:
                conn.close()
                break
            for credentials in [cluster_status.replication_credentials,
                                cluster_status.db_credentials]:
                self._db.createuser(credentials['user'],
                                    credentials['password'])

    def standby_follow(self, new_master, retries=20, retry_interval=1):
        if new_master == node_status['name']:
            logger.warning('tried to follow ourselves')
            return
        master_details = cluster_status.nodes[new_master]
        master_ip, master_port = master_details['host_ip'], DB_PORT
        if self.is_already_following(master_ip):
            logger.info('Already following {0}'.format(master_ip))
            return
        logger.debug('Preparing to follow {0}:{1}'
                     .format(master_ip, master_port))
        credentials = cluster_status.replication_credentials
        wait_for_postgres(new_master)

        if node_status.get('db') == 'master' \
                or self._is_timeline_different():
            # we decide to drop the current db and clone again in 2 cases:
            #  - we were the master but we're told to follow - this means
            #    something changed in the cluster while we were
            #    disconnected, so our state might be inconsistent
            #  - the timeline has changed, meaning we should switch to a
            #    db that was updated separately from ours; it can be
            #    impossible to merge it automatically
            self._rejoin_cluster(new_master, master_ip, master_port)

        connection_options = {
            'sslkey': SSL_POSTGRES_CLIENT_KEY,
            'sslcert': SSL_CLIENT_CERT,
            'sslrootcert': SSL_CA_CERT,
            'sslmode': 'verify-ca',
            'user': credentials['user'],
            'password': credentials['password'],
            'host': master_ip,
            'port': str(master_port)
        }
        connstring = ' '.join('{0}={1}'.format(k, v)
                              for k, v in connection_options.items())
        sudo.run([
            'follow_db',
            '--trigger-file', TRIGGER_FILE,
            '--data-dir', self._db.data_dir,
            '--owner', self._db._owner,
            '--connstring', connstring
        ])

        utils.wait_for_port(host='127.0.0.1', port=self._db.port)
        logger.debug('done waiting')

        node_status['db'] = 'standby'
        node_status['db_following'] = master_ip

        for retry in range(retries):
            if self.is_already_following(master_ip):
                return
            else:
                logger.debug('retrying post-follow check ({0}/{1})'
                             .format(retry, retries))
                time.sleep(retry_interval)
        else:
            raise RuntimeError('Following {0} failed'.format(master_ip))

    def _rejoin_cluster(self, new_master, master_ip, master_port):
        logger.debug('Rejoining cluster! Deleting old db...')
        sudo.run(['recreate_db_directory', '--data-dir', self._db.data_dir,
                  '--owner', self._db._owner])
        new_db = Database(data_dir=self._db.data_dir)
        new_db.replication.standby_clone(master_ip, master_port=master_port)
        logger.debug('DB cloned successfully')

    def is_already_following(self, master_ip):
        """Is the current node already replicating from master?
        """
        if node_status.get('db_following') != master_ip:
            return False

        try:
            with database_connection(cluster_status.master,
                                     replication=True) as conn:
                with conn.cursor() as cur:
                    cur.execute('IDENTIFY_SYSTEM;')
                    results = cur.fetchall()[0]
                    master_systemid, master_timeline = results[0], results[1]
        except psycopg2.DatabaseError:
            return False

        try:
            with database_connection(replication=True) as conn:
                with conn.cursor() as cur:
                    cur.execute('IDENTIFY_SYSTEM;')
                    results = cur.fetchall()[0]
                    local_systemid, local_timeline = results[0], results[1]
        except psycopg2.DatabaseError:
            return False

        return local_systemid == master_systemid \
            and local_timeline == master_timeline

    def is_already_master(self):
        self._db._wait_until_ready()
        return node_status.get('db') == 'master'

    def _is_timeline_different(self):
        master_timeline = _get_timeline()
        logger.debug('master_timeline {0}'.format(master_timeline))
        try:
            local_timeline = _get_timeline(master=False)
        except psycopg2.DatabaseError as e:
            logger.debug('local_timeline get error: {0}'.format(e))
            # local db doesn't have a timeline? it's broken, we need to clone
            return True

        logger.debug('local_timeline {0}'.format(local_timeline))
        return local_timeline != master_timeline


def configure(**kwargs):
    logger.debug('Database cluster nodes: {0}'
                 .format(cluster_status.db_nodes.keys()))
    original_db = OriginalDatabase()
    subprocess.check_call(['usermod', '-G', utils.CLUSTER_OS_GROUP,
                          original_db._owner])
    client = consul.get_consul_client()
    ca_crt, ca_key = ssl.get_ca_cert(client)
    client_cert, client_key = ssl.create_cert(
        ca_crt, ca_key, ip=node_status['ip'],
        common_name='postgresql_client_{0}'.format(node_status['name']))
    shutil.move(client_cert, SSL_CLIENT_CERT)
    shutil.move(client_key, SSL_CLIENT_KEY)
    shutil.copy(SSL_CLIENT_KEY, SSL_POSTGRES_CLIENT_KEY)
    shutil.move(ca_crt, SSL_CA_CERT)

    os.chmod(SSL_CLIENT_KEY, 0644)
    os.chown(SSL_CLIENT_KEY, pwd.getpwnam(original_db._owner).pw_uid,
             grp.getgrnam(utils.CLUSTER_OS_GROUP).gr_gid)

    os.chmod(SSL_POSTGRES_CLIENT_KEY, 0600)
    os.chown(SSL_POSTGRES_CLIENT_KEY, pwd.getpwnam(original_db._owner).pw_uid,
             grp.getgrnam(utils.CLUSTER_OS_GROUP).gr_gid)

    node_num = len(cluster_status.db_nodes) + 1
    cluster_status.db_nodes[node_status['name']] = {
        'num': node_num,
        'name': node_status['name'],
        'port': original_db.port
    }
    data_dir = kwargs.get('data_dir', '/var/pgdata')
    node_status['postgresql_data_dir'] = data_dir
    if utils.is_master():
        os.remove(os.path.join(ORIGINAL_DATA_DIR, 'pg_hba.conf.tmp'))
        os.remove(os.path.join(ORIGINAL_DATA_DIR, 'pg_hba.conf.backup'))
        db = original_db.clone(data_dir)
    else:
        db = Database.create(data_dir)

    db.configure()

    if utils.is_master():
        logger.info('Database: configuring as master')
        _configure_master(db)

    cluster_status.nodes[node_status['name']]['db_port'] = db.port

    restservice_config = utils.load_restservice_config()
    cloudify_db = restservice_config['postgresql_db_name']
    cloudify_user = cluster_status.db_credentials['user']
    # store here to use it again in update db settings handler
    node_status['db_config'] = {
        'cloudify_db': cloudify_db,
        'cloudify_user': cloudify_user,
        'replication_user': DB_REPLICATION_USER
    }

    _update_logstash_config(db_host='127.0.0.1', db_port=db.port)
    _update_postgres_config(db_host='127.0.0.1', db_port=db.port)
    _update_stage_config(db_host='localhost', db_port=db.port)


def start(**kwargs):
    data_dir = node_status['postgresql_data_dir']
    db = Database(data_dir)
    original_db = OriginalDatabase()

    new_connkwargs = cluster_status.db_nodes[node_status['name']]
    new_connkwargs['port'] = db.port
    cluster_status.db_nodes[node_status['name']] = new_connkwargs

    if utils.is_master():
        db.start()
    else:
        db.replication.standby_follow(cluster_status.master)

    _update_restservice(db)
    original_db.stop()
    original_db.disable()
    _create_consul_db_service()


def _update_stage_config(db_host, db_port):
    """Set stage to use the new cluster database."""
    try:
        with open(services.STAGE_CONFIG_PATH, 'r+') as f:
            stage_config = json.load(f)
            db_url = urlparse.urlparse(stage_config['db']['url'])
            stage_credentials, _, stage_db_addr = db_url.netloc.partition('@')
            new_stage_db_addr = '{0}:{1}'.format(db_host, db_port)

            logger.debug('changing stage db from {0} to {1}'
                         .format(stage_db_addr, new_stage_db_addr))
            stage_config['db']['url'] = urlparse.urlunparse(
                db_url._replace(netloc='{0}@{1}'.format(stage_credentials,
                                                        new_stage_db_addr)))

            f.seek(0)
            f.truncate()
            json.dump(stage_config, f, sort_keys=True, indent=4)
    except (IOError, ValueError, KeyError):
        logger.exception('Could not update Stage config')
    else:
        services.STAGE.restart()


def _update_logstash_config(db_host, db_port):
    """Set logstash to send logs to the new cluster database."""
    logger.info('Updating logstash to work in cluster mode')
    with open(services.LOGSTASH_CONFIG_PATH, 'r+') as f:
        data = f.read()
        data = data.replace('postgresql://localhost:5432',
                            'postgresql://{}:{}'.format(db_host, db_port))
        f.seek(0)
        f.truncate()
        f.write(data)
    services.LOGSTASH.restart()


def _update_postgres_config(db_host, db_port):
    logger.info('Updating postgresql to work in cluster mode')
    with open(services.POSTGRESQL_PGPASS, 'a+') as pgpass:
        first_line = pgpass.readlines()[0]
        config = first_line.split(':')
        config[0] = db_host
        config[1] = str(db_port)
        pgpass.write('\n{0}'.format(':'.join(config)))


def _configure_master(db):
    db.config.deploy_config()

    client = consul.get_consul_client()
    ca_crt, ca_key = ssl.get_ca_cert(client)
    postgres_ca_path = os.path.join(db.data_dir, 'root.crt')
    shutil.copy(ca_crt, postgres_ca_path)
    server_cert, server_key = ssl.create_cert(
        ca_crt, ca_key, ip=node_status['ip'],
        common_name='postgresql_{0}'.format(node_status['name']))
    postgres_key_path = os.path.join(db.data_dir, 'server.key')
    postgres_cert_path = os.path.join(db.data_dir, 'server.crt')
    shutil.copy(server_cert, postgres_cert_path)
    shutil.copy(server_key, postgres_key_path)
    db_owner = pwd.getpwnam(db._owner)
    os.chmod(postgres_key_path, stat.S_IRUSR | stat.S_IWUSR)  # 0600
    for filename in [postgres_cert_path, postgres_key_path, postgres_ca_path]:
        os.chown(filename, db_owner.pw_uid, db_owner.pw_gid)

    # start the db so that we can create the replication user & database,

    # we can't wait for the db to be writable yet, because that requires
    # an actual db connection - we haven't created the db user yet.
    # Instead, we'll just wait for the recovery.done file to exist, at which
    # point we'll be able to create the user.

    # Note: db is in recovery mode, because we're cloning the cloudify
    # database instead of using the original. (so that user data is never lost
    # in case of a failure later)
    db.start(wait_writable=False)
    _wait_for_recovery(db.data_dir)

    replication_password = base64.urlsafe_b64encode(os.urandom(16))
    db.createuser(DB_REPLICATION_USER, replication_password)
    cluster_status.replication_credentials = {
        'user': DB_REPLICATION_USER,
        'password': replication_password
    }

    db_password = base64.urlsafe_b64encode(os.urandom(16))
    db.createuser(DB_QUERY_USER, db_password)
    cluster_status.db_credentials = {
        'user': DB_QUERY_USER,
        'password': db_password
    }
    restservice_config = utils.load_restservice_config()
    db.run(['psql', restservice_config['postgresql_db_name'], '-c', """
        CREATE OR REPLACE FUNCTION get_last_login() returns timestamp as $$
            SELECT max(last_login_at) FROM users
        $$ LANGUAGE SQL SECURITY DEFINER
    """])

    db.config.prepare_pg_hba()
    db.stop()
    node_status['db'] = 'master'


def _update_restservice(db):
    # after the new database is started, make sure to update the restservice
    # config so that it is used
    utils.update_restservice_config({
        'postgresql_host': '127.0.0.1:{0}'.format(db.port)
    })
    services.RESTSERVICE.restart()


def _create_consul_db_service():
    consul.write_config_file('database_service', {
        'service': {
            'name': 'database',
            'id': 'database',
            'address': node_status['ip'],
            'port': DB_PORT
        }
    })

    consul.write_config_file('db_following_check', {
        'check': {
            'id': 'db_following_check',
            'name': 'db following check',
            'service_id': 'database',
            'ttl': '5s',
        }
    })

    consul.write_config_file('db_sql_check', {
        'check': {
            'id': 'db_sql_check',
            'name': 'db sql check',
            'service_id': 'database',
            'ttl': '5s'
        }
    })

    checks = node_status['checks']
    checks.update({
        'check_db_following': 'db_following_check',
        'check_local_db': 'db_sql_check'
    })
    node_status['checks'] = checks


def wait_for_postgres(node=None, retries=20, retry_interval=1):
    """Wait until the postgres specified by connkwargs is ready and writable.

    Note: this is different than just waiting until the port is open,
    because a database starting up from a recovery will accept connections
    before it is actually operable. It will error on writing until recovery
    is finished.
    """
    for retry in range(retries):
        try:
            conn = database_connection(node, replication=True)
        except psycopg2.DatabaseError as e:
            time.sleep(retry_interval)
            display_name = 'local' if node is None else node
            logger.debug('Postgresql {0} not ready yet (retry {1}): {2}'
                         .format(display_name, retry, e))
            continue
        cur = conn.cursor()
        # when the database starts, it's in read-only mode while it
        # synchronizes the copied data. Retry doing a write operation
        # (creating a table) until it's done.
        try:
            cur.execute('IDENTIFY_SYSTEM;')
            results = cur.fetchall()
        except psycopg2.DatabaseError as e:
            time.sleep(retry_interval)
            display_name = 'local' if node is None else node
            logger.debug('Postgresql {0} still in read-only mode '
                         '(retry {1}): {2}'
                         .format(display_name, retry, e))
            continue
        finally:
            conn.close()

        if results:
            break
        else:
            time.sleep(retry_interval)


def _wait_for_recovery(data_dir, interval=1):
    """Wait until recovery is done on a local postgres database.

    This is different than waiting until the database is writable, because
    a replica won't be writable even after recovery is done.

    Note that this checks for the recovery.done file existing, so this will
    only work for the local database.
    """
    logger.debug('Waiting for recovery: {0}'.format(data_dir))
    recovery_file = os.path.join(data_dir, 'recovery.conf')
    done_file = os.path.join(data_dir, 'recovery.done')
    while True:
        if os.path.exists(done_file):
            logger.debug('Recovery done!')
            # sleep for one interval more to allow pg to actually settle
            time.sleep(interval)
            return
        if not os.path.exists(recovery_file):
            raise RuntimeError('Waiting for recovery but recovery file does '
                               'not exist at {0}'.format(recovery_file))
        time.sleep(interval)


def _get_timeline(master=True):
    """Get the postgresql replication timeline of the specified node.

    When the timeline changes, the replica nodes need to be cloned again.
    """
    target_node = cluster_status.master if master else node_status['name']
    with database_connection(target_node, replication=True) as conn:
        with conn.cursor() as cur:
            cur.execute('IDENTIFY_SYSTEM;')
            result = cur.fetchall()[0][1]
    if not result:
        return None
    return result


def database_connection(node=None, cluster_status=cluster_status, verify=True,
                        **override_kwargs):
    if psycopg2 is None:
        raise RuntimeError('psycopg2 not available - cannot connect to '
                           'the database')
    if node is None:
        node = node_status['name']

    with tempfile.NamedTemporaryFile(delete=False) as f:
        key_copy_filename = f.name
    shutil.copy(SSL_CLIENT_KEY, key_copy_filename)
    os.chmod(key_copy_filename, 0600)
    connect_kwargs = {
        'host': cluster_status.nodes[node]['host_ip'],
        'port': cluster_status.db_nodes[node]['port'],
        # avoid hanging on a stalled connection for too long - use a timeout
        # by default
        'connect_timeout': POSTGRESQL_CONNECT_TIMEOUT,
        'sslkey': key_copy_filename,
        'sslcert': SSL_CLIENT_CERT,
        'sslrootcert': SSL_CA_CERT
    }
    if verify:
        connect_kwargs['sslmode'] = 'verify-ca'
    connect_kwargs.update(cluster_status.replication_credentials)
    connect_kwargs.update(override_kwargs)

    if 'database' not in connect_kwargs:
        connect_kwargs['database'] = utils.load_restservice_config()[
            'postgresql_db_name']

    if 'replication' in connect_kwargs:
        return _ReplicationConnection(**connect_kwargs)
    try:
        return psycopg2.connect(**connect_kwargs)
    finally:
        os.unlink(key_copy_filename)


# _ReplicationConnection and _ReplicationCursor are shims to allow using
# a replication connection, with the same interface as a regular psycopg2
# connection.

# psycopg2 version 2.7 will support replication, so when we upgrade to that,
# we will be able to remove this implementation and use psycopg2's instead

# we're just using subprocess with `psql -c "query"` to support replication
# queries
class _ReplicationConnection(object):
    def __init__(self, **connect_kwargs):
        if 'database' in connect_kwargs:
            connect_kwargs['dbname'] = connect_kwargs.pop('database')
        self._connect_kwargs = connect_kwargs

    @property
    def _db_uri(self):
        return ' '.join('{0}={1}'.format(k, v)
                        for k, v in self._connect_kwargs.items())

    def cursor(self):
        return _ReplicationCursor(self._db_uri)

    def close(self):
        pass

    def __enter__(self):
        return self

    def __exit__(self, exc, val, tb):
        self.close()


class _ReplicationCursor(object):
    delimiter = '|'

    def __init__(self, _db_uri):
        self._db_uri = _db_uri
        self._results = None

    def __enter__(self):
        return self

    def __exit__(self, exc, val, tb):
        self._results = None

    def execute(self, query, args=None):
        if args is not None:
            raise ValueError('Replication cursors dont support queries with '
                             'arguments')
        try:
            results = subprocess.check_output([
                'psql',
                self._db_uri,
                '-c', query,
                '-F"{0}"'.format(self.delimiter),
                '-A', '-t'
            ], stderr=subprocess.STDOUT)
        except subprocess.CalledProcessError as e:
            raise psycopg2.DatabaseError(e.output)
        self._results = self._process_results(results)

    def _process_results(self, results):
        for row in results.split('\n'):
            if row:
                yield [field.strip('"') for field in row.split(self.delimiter)]

    def fetchone(self):
        return next(self._results)

    def fetchall(self):
        return list(self._results)
