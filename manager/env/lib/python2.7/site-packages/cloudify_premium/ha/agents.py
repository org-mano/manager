########
# Copyright (c) 2016 GigaSpaces Technologies Ltd. All rights reserved
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#        http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
#    * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#    * See the License for the specific language governing permissions and
#    * limitations under the License.

import os
import grp
import pwd
import stat
import errno
import pickle
import celery
import socket
import logging

from collections import namedtuple

from cloudify_premium.ha import cluster_status, nginx, node_status, utils
from cloudify_premium.ha.database import database_connection


logger = logging.getLogger(__name__)
Task = namedtuple('Task', ['name', 'args', 'kwargs'])
CELERY_WORK_DIR = '/opt/mgmtworker/work'
BROKER_CONFIG = '/opt/mgmtworker/work/broker_config.json'
MGMTWORKER_OS_USER = 'cfyuser'


class AgentsController(object):
    def __init__(self, celery_client=None):
        self._celery_client = celery_client

    @property
    def celery_client(self):
        if self._celery_client is None:
            self._celery_client = get_celery_client()
        return self._celery_client

    def send_task(self, task, target):
        self.celery_client.send_task(
            name=task.name,
            args=task.args,
            kwargs=task.kwargs,
            target=target,
            queue=target
        )

    def broadcast_task(self, task):
        for worker in self.get_workers():
            logger.debug('Sending {0} to worker {1}'
                         .format(task.name, worker))
            self.send_task(task, worker)

    def get_workers(self):
        for name in self.celery_client.control.inspect().active():
            user, _, worker_name = name.partition('@')
            if worker_name != 'cloudify.management':
                yield worker_name

    def send_update(self):
        task = Task('cluster-update', (), {
            'nodes': cluster_status.agent_settings.values()
        })
        try:
            self.broadcast_task(task)
        except socket.error as e:
            got_errno = e.errno
            # some versions of pyamqp wrap the socket.error in another
            # socket.error...
            if got_errno is None:
                got_errno = e[0].errno
            if got_errno == errno.ECONNREFUSED:
                # connection refused - rabbitmq is not running, so there's no
                # agents to update
                return
            else:
                raise


def get_celery_client():
    client = celery.Celery()
    os.environ['CELERY_WORK_DIR'] = CELERY_WORK_DIR
    client.config_from_object('cloudify.broker_config')
    return client


def _get_context(conn):
    with conn.cursor() as cur:
        cur.execute('SELECT context FROM provider_context')
        rows = cur.fetchall()

    if len(rows) != 1:
        raise ValueError('Expected 1 provider_context row, but got {0}'
                         .format(len(rows)))

    pickled_context = rows[0][0]
    return pickle.loads(pickled_context)


def _store_context(conn, ctx):
    pickled_context = pickle.dumps(ctx)
    with conn.cursor() as cur:
        cur.execute('UPDATE provider_context SET context=%s',
                    (bytearray(pickled_context), ))
        conn.commit()


def _update_context(ctx):
    """Mutate the passed ctx to contain the current cluster state."""
    stored_cloudify_agent = node_status.get('cloudify_agent')

    if stored_cloudify_agent:
        ctx['cloudify']['cloudify_agent'] = stored_cloudify_agent

    # make sure the current master - ie. ourselves - is the first in the list
    agent = dict(stored_cloudify_agent)
    if 'cluster' in agent:
        del agent['cluster']
    other_settings = [n for n in cluster_status.agent_settings.values()
                      if n['broker_ip'] != stored_cloudify_agent['broker_ip']]
    ctx['cloudify']['cloudify_agent']['cluster'] = \
        [agent] + other_settings


def update_agent_context():
    """Put the updated cluster data in provider_context in the database."""

    with database_connection(host='127.0.0.1',
                             **utils.cloudify_database_credentials()) as conn:
        ctx = _get_context(conn)
        _update_context(ctx)
        _store_context(conn, ctx)


def store_agent_context():
    # this runs on the original database - before setting up the cluster one;
    # disable verification because that database has no ssl infra yet
    with database_connection(host='127.0.0.1', verify=False,
                             **utils.cloudify_database_credentials()) as conn:
        ctx = _get_context(conn)
    cloudify_agent = ctx['cloudify']['cloudify_agent']
    with open(nginx.INTERNAL_SSL_CERT_PATH) as f:
        cloudify_agent['internal_cert'] = f.read()
    node_status['cloudify_agent'] = cloudify_agent
    cluster_status.agent_settings[node_status['name']] = cloudify_agent


def configure(**kwargs):
    # allow cluster to read broker_config - needed to get a celery client
    os.chown(BROKER_CONFIG, pwd.getpwnam(MGMTWORKER_OS_USER).pw_uid,
             grp.getgrnam(utils.CLUSTER_OS_GROUP).gr_gid)
    os.chmod(BROKER_CONFIG, os.stat(BROKER_CONFIG).st_mode | stat.S_IRGRP)


_agents = AgentsController()
send_update = _agents.send_update
